<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>r | Maria Dermit</title>
    <link>/tags/r/</link>
      <atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <description>r</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>¬© Maria Dermit, {2020}</copyright><lastBuildDate>Wed, 20 Jan 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/images/icon_hu89765a528fbe3e89fbea23b995128687_292554_512x512_fill_lanczos_center_2.png</url>
      <title>r</title>
      <link>/tags/r/</link>
    </image>
    
    <item>
      <title>Joining the RStudio Tidyverse Instructor community</title>
      <link>/2021-01-20-rstudio-instructor-certification-tidyverse/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/2021-01-20-rstudio-instructor-certification-tidyverse/</guid>
      <description>
&lt;script src=&#34;../../2021-01-20-rstudio-instructor-certification-tidyverse/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#fundations-of-my-motivation&#34;&gt;Fundations of my motivation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#why-i-decided-to-become-an-rstudio-tidyverse&#34;&gt;Why I decided to become an RStudio Tidyverse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#during-the-training&#34;&gt;During the training&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#between-training-and-exam&#34;&gt;Between training and exam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#during-the-teaching-exam&#34;&gt;During the teaching exam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#during-the-tidyverse-exam&#34;&gt;During the Tidyverse exam&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#voil√†&#34;&gt;Voil√†!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;fundations-of-my-motivation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Fundations of my motivation&lt;/h1&gt;
&lt;p&gt;Early 2020, in a pre-pandemic world, I attended my first &lt;a href=&#34;https://mine-cetinkaya-rundel.github.io/tidy-up-ds/2020-02-london/tidy-up.html#1&#34;&gt;Rladies meetup in London&lt;/a&gt; by
&lt;a href=&#34;https://education.rstudio.com/author/mine/&#34;&gt;Mine Cetinkaya-Rundel&lt;/a&gt;. Part of the reasons I decided to attended was because my husband was going to be away for the foreseeable months, so I decided to give myself the chance to connect with other Rladies. It was only few months before that meetup that I started using the Tidyverse, although I used R for many years in the past. It was a fantastic talk where I met some very cool Rladies and I got super impressed by Mine‚Äôs teaching abilities.&lt;/p&gt;
&lt;p&gt;During the past year, and because of continous lockdowns and WFH, I really dived into the Tidyverse: I joint LatinR talks, participated in Rladies Barcelona Florence Nightingale content, I watched Tidytuesday screencasts, opened a blog with Hugo, Rblogdown and Netlify (thanks to the amazing resources shared by &lt;a href=&#34;https://education.rstudio.com/trainers/people/hill+alison/&#34;&gt;Alison Hill&lt;/a&gt;). I could easily say that the Tidyverse mission üõ∞ keep my mental health afloat during such difficult times.&lt;/p&gt;
&lt;p&gt;Moreover, during the summer of 2020 I got some formal teaching training from university of London where I learn concepts like Blooms taxonomy and I started to give by-weekly workshops for biology researcher co-workers of mine where I introduce them to ggplot2 and statistical concepts such as correlation.&lt;/p&gt;
&lt;p&gt;All these things had a direct impact on my research career; for instance I published my
first R package and gave my first EuroBioconductor &lt;a href=&#34;https://docs.google.com/presentation/d/16WN2ldl0r4f5Iv1pR5DAdSIC29H5JcM1Dr0RrYH9qx4/edit#slide=id.p&#34;&gt;short talk&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-i-decided-to-become-an-rstudio-tidyverse&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why I decided to become an RStudio Tidyverse&lt;/h1&gt;
&lt;p&gt;I decided to get certificated for several reasons:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Getting additional formal training on how to teach. I felt I and my audience could benefit more the better trained for training I would be.&lt;/li&gt;
&lt;li&gt;Pushing myself to really know inside out the Tidyverse. Getting the training forced me to read the R4DS book and doing the exercises thoroughly. I used additional fantastic resources such as &lt;a href=&#34;https://datasciencebox.org/&#34;&gt;https://datasciencebox.org/&lt;/a&gt;. Later, I learn that there are book clubs for some of the most popular R books, something that I somewhat missed, but I am very excited to join in 2021 the tidymodels book club organised by &lt;a href=&#34;https://twitter.com/JonTheGeek&#34;&gt;Jon Harmon&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The RStudio Instructor training journey has properly equipped me to do and teach data science! This process pushed me out of my comfort zone for which I will be forever grateful.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;during-the-training&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;During the training&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Instructor training covering modern teaching methods&lt;/strong&gt;. Materials for this training are &lt;a href=&#34;https://drive.google.com/drive/folders/13ohFt3D0EJ5PDbMaWTxnHH-hwA7G0IvY&#34;&gt;available here&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was a two half days course where &lt;a href=&#34;https://third-bit.com/&#34;&gt;Greg Wilson&lt;/a&gt; lead such inspiring modules. What I like the most was feeling part of the learning community, the interactivity of the modules and genuinely learning about evidence-based effective teaching methods.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Be nice, the rest is on the details &lt;strong&gt;‚ÄìGreg&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/div&gt;
&lt;div id=&#34;between-training-and-exam&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Between training and exam&lt;/h1&gt;
&lt;div id=&#34;materials&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Materials&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Books&lt;/strong&gt;.
Reading the book &lt;a href=&#34;https://teachtogether.tech/&#34;&gt;Teaching Tech Together&lt;/a&gt; written by Greg. The book is currently undergoing translation into Spanish by a team of volunteers and I am honored to be among them thanks to &lt;a href=&#34;https://education.rstudio.com/trainers/people/bellini_saibene+yanina/&#34;&gt;Yanina Bellini Saibene&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Guides&lt;/strong&gt;.
Going through &lt;a href=&#34;https://github.com/rstudio-education/r4ds-instructors&#34;&gt;R4DS instructor‚Äôs guide&lt;/a&gt; which has learning objectives and key points for each chapter of R4DS book.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Concept maps&lt;/strong&gt;.
Building concept maps to design lessons taking into account cognitive load is a big part of the training. When preparing for the two exams I found &lt;a href=&#34;https://github.com/rstudio/concept-maps/tree/master/es&#34;&gt;this resource&lt;/a&gt; extremely useful to check I was building an accurate mental model of the topics covered in R4DS. I built myself quite a lot of mental models that you can find here&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Greg also asked us to send an email with what we remember and so I did this concept map (there is a lot of information buried beneath my bad hand writing)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;RStudioInstructor_1month_MariaDermit.jpg&#34; /&gt;&lt;/p&gt;
&lt;ol start=&#34;4&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Watching and reading other people‚Äôs experiences&lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=SJmfXYd0hOU&amp;amp;feature=emb_logo&#34;&gt;Process to become a certified Rstudio instructor&lt;/a&gt; a video where some Mi-useRs &lt;a href=&#34;https://medium.com/@doritolay/introducing-mir-a-community-for-underrepresented-users-of-r-7560def7d861&#34;&gt;(minority R users)&lt;/a&gt; talk about their experiences and motivations to become a certified Rstudio instructor.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://yabellini.netlify.app/post/rstudiocertification/&#34;&gt;Obtaining RStudio certification. A shared path&lt;/a&gt; a post by Yanina on her journey to obtain RStudio certification.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://bcullen.rbind.io/post/2020-09-03-reflections-on-rstudio-instructor-training/&#34;&gt;Reflections&lt;/a&gt; by &lt;a href=&#34;https://education.rstudio.com/trainers/people/cullen+brendan/&#34;&gt;Brendan Cullen‚Äôs&lt;/a&gt; on RStudio Instructor Training .&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://silvia.rbind.io/2020-10-07-rstudio-instructor-certification-tidyverse/&#34;&gt;Overview&lt;/a&gt; by &lt;a href=&#34;https://education.rstudio.com/trainers/people/canelon+silvia/&#34;&gt;Silvia Canelon&lt;/a&gt;
of the RStudio Instructor certification process. Check her post since she has an amazing collection of resources to support anyone on their certification journey.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;5&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;strong&gt;Active learning &lt;/strong&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;With some of the materials I use during my learning, I created some exercises using the &lt;a href=&#34;https://rstudio.github.io/learnr/&#34;&gt;learnr&lt;/a&gt; package, which is such a powerful and versatile way to create interactive exercises.
&lt;a href=&#34;https://clif.shinyapps.io/01-Replacement-es/&#34;&gt;This&lt;/a&gt; is my humble contribution to fading exercises with &lt;a href=&#34;https://github.com/allisonhorst/palmerpenguins&#34;&gt;Penguins&lt;/a&gt; and I hope to extend these materials in &lt;a href=&#34;https://user2021.r-project.org/&#34;&gt;user!2021&lt;/a&gt; later this year&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;I also gave a mocked presentation to &lt;a href=&#34;https://education.rstudio.com/trainers/people/quiroga+riva/&#34;&gt;Riva Quiroga&lt;/a&gt; and &lt;a href=&#34;https://education.rstudio.com/trainers/people/bellini_saibene+yanina/&#34;&gt;Yanina Bellini&lt;/a&gt; over Zoom and received extremely useful feedback. Gracias chicas!!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;during-the-teaching-exam&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;During the teaching exam&lt;/h1&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A 90-minute &lt;strong&gt;teaching exam&lt;/strong&gt; based on content from the instructor training. This includes a 15-minute demonstration lesson and a written component. Mine was on &lt;a href=&#34;https://r4ds.had.co.nz/workflow-projects.html&#34;&gt;RStudio projects&lt;/a&gt; and my learner persona was &lt;a href=&#34;https://docs.google.com/presentation/d/11CN4Ox8k-zeFEoXJYkbWTNN0V94pyS-T8oHMmBG34xU/edit#slide=id.ga7003f49f1_0_78&#34;&gt;Lovorka&lt;/a&gt;. You can see my contribution &lt;a href=&#34;https://docs.google.com/presentation/d/124emaF1lpe4PwVC2zy2bxN1-ckGynlPBkFxVRh7a0r8/edit&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;during-the-tidyverse-exam&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;During the Tidyverse exam&lt;/h1&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;A 90-minute &lt;strong&gt;Tidyverse exam&lt;/strong&gt; to test your knowledge of the subject matter in &lt;a href=&#34;https://r4ds.had.co.nz/&#34;&gt;R for Data Science&lt;/a&gt; (make sure to check the &lt;a href=&#34;https://education.rstudio.com/trainers/#faq&#34;&gt;program FAQs&lt;/a&gt; for information about the Shiny exam). I hope to share my exercise soon.&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div id=&#34;voil√†&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Voil√†!&lt;/h1&gt;
&lt;p&gt;Joining this community is a dream‚Ä¶ that may become true for you too? üçé&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Transfer learning for spatial proteomics</title>
      <link>/2021-01-20-transfer-learning-for-spatial-proteomics/</link>
      <pubDate>Wed, 20 Jan 2021 00:00:00 +0000</pubDate>
      <guid>/2021-01-20-transfer-learning-for-spatial-proteomics/</guid>
      <description>
&lt;script src=&#34;../../2021-01-20-transfer-learning-for-spatial-proteomics/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#introduction&#34;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#getting-the-data&#34;&gt;Getting the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#quetting-auxiliary-annotation-biomart-query&#34;&gt;Quetting auxiliary annotation (Biomart Query)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#nearest-neighbour-transfer-learning&#34;&gt;Nearest neighbour transfer learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusions&#34;&gt;Conclusions&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# loading libraries
# clearing environment bc https://support.bioconductor.org/p/p132709/
rm(list = ls())
library(pRoloc)
library(pRolocdata)
library(BiocStyle)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;introduction&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Within the cell, the localization of a given protein is determined by its biological
function. Subcellular proteomics is the method to study protein sub-cellular
localization in a systematic manner. There are two complementary ways to analysis localized proteins:
- On one hand biochemical sub-cellular fractionation experiments allow empirical quantification of protein across sub-cellular and sub-organellar compartments. Proteins are allocated to a given subcellular niche
if the detected intensity is higher than a threshold. We can say that this type of data has high signal-to-noise ratio, but is available in limited amounts (&lt;em&gt;primary&lt;/em&gt; data).
- On the other hand, databases such as &lt;a href=&#34;http://geneontology.org/&#34;&gt;GO&lt;/a&gt; contain large amount of information about sub-cellular proteins localisation, but this is information is blended for a many biological systems. We can say that this type of data has high low signal-to-noise, but is available in large amounts (&lt;em&gt;auxiliary&lt;/em&gt; data).&lt;/p&gt;
&lt;p&gt;So we want to know &lt;em&gt;how to optimally combine&lt;/em&gt; primary and auxiliary data.üíπ&lt;/p&gt;
&lt;p&gt;To do so, we need to weight both types of data. If we imagine a multivariate
distribution (like a &lt;a href=&#34;https://github.com/TommyJones/tidylda&#34;&gt;Dirichlet distribution&lt;/a&gt;) were all the components take values between (0,1) and all values sum up to one, we can imagine that a weight of 1 indicates that the final annotation rely exclusively on the experimental data and ignore completely the auxiliary data and a weight of 0 represents the opposite situation, where the primary data is ignored and only the auxiliary data is considered.&lt;/p&gt;
&lt;p&gt;We could use a &lt;em&gt;transfer learning&lt;/em&gt; algorithm to efficiently complement the primary data with auxiliary data without compromising the integrity of the former. This is implemented in the &lt;code&gt;pRoloc&lt;/code&gt; package and it was published by &lt;a href=&#34;https://lgatto.github.io/pRoloc/reference/knntlClassification.html&#34;&gt;Breckels et al&lt;/a&gt; and expanded by
&lt;a href=&#34;https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006516&#34;&gt;Crook et al&lt;/a&gt; using a Bayesian approach. In this post I will step-by-step walk through KNN transfer learning.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-the-data&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Getting the data&lt;/h1&gt;
&lt;p&gt;We start with &lt;code&gt;HEK293T2011&lt;/code&gt; proteomics data available in the &lt;em&gt;&lt;a href=&#34;https://bioconductor.org/packages/3.10/pRolocdata&#34;&gt;pRolocdata&lt;/a&gt;&lt;/em&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(HEK293T2011)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we do MSnSet we can see that this is a &lt;a href=&#34;http://www.bioconductor.org/packages/release/bioc/html/MSnbase.html&#34;&gt;MSnSet&lt;/a&gt; instance, an efficient and established to store and handle MS data and metainformation efficiently. I am not going to discuss much about this class of objects since the field is moving towards other types of data storage such as &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/SummarizedExperiment.html&#34;&gt;SummarizedExperiment objects&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;We can have an overview of of the structure of this dataset looks like&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;HEK293T2011&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can also get an overview experimental data and query how many proteins across how many conditions were quantified.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(exprs(HEK293T2011),2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             X113      X114       X115      X116      X117       X118       X119
## O00767 0.1360547 0.1495961 0.10623931 0.1465050 0.2773137 0.14294025 0.03796970
## P51648 0.1914456 0.2052463 0.05661169 0.1651138 0.2366302 0.09964387 0.01803788
##               X121
## O00767 0.003381233
## P51648 0.027270640&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;dim(exprs(HEK293T2011))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1371    8&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What is important to know is that 1371 proteins were quantified across eight iTRAQ 8-plex labelled fractions (
one could know a bit more about the experiment on &lt;code&gt;?HEK293T2011&lt;/code&gt;))&lt;/p&gt;
&lt;p&gt;Next thing we can do is see how well these organelles have been resolved in the experiment using a PCA plot&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot2D(HEK293T2011)
addLegend(HEK293T2011, where = &amp;quot;topright&amp;quot;, cex = 0.6)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:unnamed-chunk-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;../../2021-01-20-transfer-learning-for-spatial-proteomics/index_files/figure-html/unnamed-chunk-5-1.png&#34; alt=&#34;PCA plot of `HEK293T2011`&#34; width=&#34;672&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: PCA plot of &lt;code&gt;HEK293T2011&lt;/code&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We see that some organelles such as cytosol and cytosol/nucleus are well resolved - and so they will get a high weigh- while others such as the Golgi or the ER are less so - so they will get a low weight.
There are some proteins that do not get annotation because the resolution of the experiment did not allow so.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;quetting-auxiliary-annotation-biomart-query&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Quetting auxiliary annotation (Biomart Query)&lt;/h1&gt;
&lt;p&gt;Next thing we can do is get auxiliary data. We can do so by querying &lt;em&gt;&lt;a href=&#34;https://bioconductor.org/packages/3.10/biomaRt&#34;&gt;biomaRt&lt;/a&gt;&lt;/em&gt; and storing the annotation as an &lt;code&gt;AnnotationParams&lt;/code&gt; object. Again, this is part of the &lt;em&gt;&lt;a href=&#34;https://bioconductor.org/packages/3.10/pRoloc&#34;&gt;pRoloc&lt;/a&gt;&lt;/em&gt; package, and it has been created for efficient data handling.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ap &amp;lt;- setAnnotationParams(inputs =
                              c(&amp;quot;Human genes&amp;quot;,
                                &amp;quot;UniProtKB/Swiss-Prot ID&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Connecting to Biomart...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can access this instance with&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getAnnotationParams()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Object of class &amp;quot;AnnotationParams&amp;quot;
##  Using the &amp;#39;ENSEMBL_MART_ENSEMBL&amp;#39; BioMart database
##  Using the &amp;#39;hsapiens_gene_ensembl&amp;#39; dataset
##  Using &amp;#39;uniprotswissprot&amp;#39; as filter
##  Created on Tue Jan 26 15:15:19 2021&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can annotate our innitial &lt;code&gt;HEK293T2011&lt;/code&gt; data by creating a new &lt;code&gt;MSnSet&lt;/code&gt; instance populated with a GO term as a binary matrix (so the auxiliary data with information about 889 cellular compartment GO terms has been added).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;HEK293T2011goset  &amp;lt;- makeGoSet(HEK293T2011)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;nearest-neighbour-transfer-learning&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Nearest neighbour transfer learning&lt;/h1&gt;
&lt;div id=&#34;deciding-the-weight&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Deciding the weight&lt;/h2&gt;
&lt;p&gt;We could define more or less weight values between 0 and 1 depending on how granular we want to be with
our search (more weight will give finer-grained integration).For example for 3 classes, 3 weights will generate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;gtools::permutations(length(seq(0, 1, 0.5)), 3, seq(0, 1, 0.5), repeats.allowed = TRUE) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       [,1] [,2] [,3]
##  [1,]  0.0  0.0  0.0
##  [2,]  0.0  0.0  0.5
##  [3,]  0.0  0.0  1.0
##  [4,]  0.0  0.5  0.0
##  [5,]  0.0  0.5  0.5
##  [6,]  0.0  0.5  1.0
##  [7,]  0.0  1.0  0.0
##  [8,]  0.0  1.0  0.5
##  [9,]  0.0  1.0  1.0
## [10,]  0.5  0.0  0.0
## [11,]  0.5  0.0  0.5
## [12,]  0.5  0.0  1.0
## [13,]  0.5  0.5  0.0
## [14,]  0.5  0.5  0.5
## [15,]  0.5  0.5  1.0
## [16,]  0.5  1.0  0.0
## [17,]  0.5  1.0  0.5
## [18,]  0.5  1.0  1.0
## [19,]  1.0  0.0  0.0
## [20,]  1.0  0.0  0.5
## [21,]  1.0  0.0  1.0
## [22,]  1.0  0.5  0.0
## [23,]  1.0  0.5  0.5
## [24,]  1.0  0.5  1.0
## [25,]  1.0  1.0  0.0
## [26,]  1.0  1.0  0.5
## [27,]  1.0  1.0  1.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As we sayed before, HEK293T2011goset experiment has 10 subcellular compartments, and so the total combinations for 10 classes, 4 weights will be:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;th &amp;lt;- gtools::permutations(length(seq(0, 1, length.out = 4)), 10, seq(0, 1, length.out = 4), repeats.allowed = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Total combination of weights for HEK293T2011goset experiment will be 1048576.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=&#34;https://bioconductor.org/packages/3.10/pRoloc&#34;&gt;pRoloc&lt;/a&gt;&lt;/em&gt; package comes with a convenient function &lt;code&gt;thetas&lt;/code&gt; to produce such a weight matrix (because we need a theta for each of the training feature).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## marker classes for HEK293T2011
m &amp;lt;- unique(fData(HEK293T2011)$markers.tl)
m &amp;lt;- m[m != &amp;quot;unknown&amp;quot;]
th &amp;lt;- thetas(length(m), length.out=4)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;optimizing-weigth&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Optimizing weigth&lt;/h2&gt;
&lt;p&gt;We can do a grid search to determine which is the best &lt;code&gt;th&lt;/code&gt;, with the &lt;code&gt;knntlOptimisation&lt;/code&gt; function of the &lt;em&gt;&lt;a href=&#34;https://bioconductor.org/packages/3.10/pRoloc&#34;&gt;pRoloc&lt;/a&gt;&lt;/em&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;topt &amp;lt;- knntlOptimisation(HEK293T2011, HEK293T2011goset,
                          th = th,
                          k = c(3, 3),
                          fcol = &amp;quot;markers.tl&amp;quot;,
                          times = 50, 
                          method = &amp;quot;Breckels&amp;quot; )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of time, we can reduce our initial data, as it will take a long time to do this grid search (even if &lt;code&gt;knntlOptimisation&lt;/code&gt; uses parallelisation by default).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(2021)
i &amp;lt;- sample(nrow(th), 50)
topt &amp;lt;- knntlOptimisation(HEK293T2011, HEK293T2011goset,
                          th = th[i, ],
                          k = c(3, 3),
                          fcol = &amp;quot;markers.tl&amp;quot;,
                          times = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The optimisation is performed on the labelled marker examples only. &lt;code&gt;topt&lt;/code&gt; result stores all the result from the optimisation step, and in particular the observed theta weights, which can be directly plotted as shown on the bubble plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(topt)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://raw.githubusercontent.com/lgatto/pRoloc/master/vignettes/Figures/bubble-andy.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;Result stocores for the optimisation step. Note that this figure is the result using extensive optimisation on the whole HEK293T2011 dataset and auxiliary andygoset data sets, not only with only a random subset of 50 candidate weights.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We see that the cytosol and cytosol/nucleus and ER are predominantly scored with high heights, consistent with high reliability of the primary data. Golgi, PM and the 40S ribosomal clusters are scored with smaller scores, indicating a substantial benefit of the auxiliary data.&lt;/p&gt;
&lt;p&gt;The best grid search parameters can be accessed with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;getParams(topt)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that the data &lt;code&gt;HEK293T2011&lt;/code&gt; &lt;em&gt;gets annotated&lt;/em&gt; with the best parameters at the knntlOptimisation
step. We can get the best weights with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bw &amp;lt;- experimentData(HEK293T2011)@other$knntl$thetas&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;performing-transfer-learning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Performing transfer learning&lt;/h2&gt;
&lt;p&gt;To apply the best weights and learn from the auxiliary data to classify the unlabelled proteins into sub-cellular niches (present in &lt;code&gt;markers.tl&lt;/code&gt; column), we can pass the primary and auxiliary data sets, best weights, best k‚Äôs and the metadata feature data taht contains the markers definitions to the &lt;code&gt;knntlClassification&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;HEK293T2011 &amp;lt;- knntlClassification(HEK293T2011, HEK293T2011goset,
                                bestTheta = bw,
                                k = c(3, 3),
                                fcol = &amp;quot;markers.tl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this step, annotation predictors scores and parameters get added into the MSnSet data. We can access the predicted localization conveniently using the &lt;code&gt;getPredictions&lt;/code&gt; assessor.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;HEK293T2011 &amp;lt;- getPredictions(HEK293T2011, fcol = &amp;quot;knntl&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-the-results&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plotting the results&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# These functions allow to get/set the colours/points to plot organelle features 
setStockcol(paste0(getStockcol(), &amp;quot;80&amp;quot;))
#this defines the point size
ptsze &amp;lt;- exp(fData(HEK293T2011)$knntl.scores) - 1
plot2D(HEK293T2011, fcol = &amp;quot;knntl&amp;quot;, cex = ptsze)
setStockcol(NULL)
addLegend(HEK293T2011, where = &amp;quot;topright&amp;quot;,
          fcol = &amp;quot;markers.tl&amp;quot;,
          bty = &amp;quot;n&amp;quot;, cex = .7)&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;TL_PCA.png&#34; alt=&#34;&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;PCA plot of &lt;code&gt;HEK293T2011&lt;/code&gt; after transfer learning classification. The size of the points is proportional to the classification scores&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;A &lt;em&gt;weighted k-nearest neighbour transfer learning&lt;/em&gt; algorithm can be very useful to predict of protein
sub-cellular localisation using quantitative proteomics data as primary data source and Gene Ontology-derived binary data as auxiliary data source.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>EuroBioc</title>
      <link>/talk/2020-11-26-eurobioc/</link>
      <pubDate>Mon, 14 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/talk/2020-11-26-eurobioc/</guid>
      <description>
&lt;link href=&#34;../../rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;../../rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;



</description>
    </item>
    
    <item>
      <title>ISCB</title>
      <link>/talk/2020-11-21-iscb/</link>
      <pubDate>Fri, 04 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/talk/2020-11-21-iscb/</guid>
      <description>
&lt;link href=&#34;../../rmarkdown-libs/anchor-sections/anchor-sections.css&#34; rel=&#34;stylesheet&#34; /&gt;
&lt;script src=&#34;../../rmarkdown-libs/anchor-sections/anchor-sections.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;presentation-slides&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Presentation slides&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Selected talk
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.google.com/presentation/d/16WN2ldl0r4f5Iv1pR5DAdSIC29H5JcM1Dr0RrYH9qx4/edit?usp=sharing&#34;&gt;Talk slides: Peptide Correlation Analysis (PeCorA) Reveals Differential Proteoform Regulation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
